## Lista de passos que considero essenciais para a conclusão do desafio

- [x] Como medir a performance em golang? 
    - Aprendi a gerar os benchmarks e analisar os principais indicadores de performance (detalhes sobre os comandos em LEARNING.md)
    - Deixei o exemplo prático utilizado na pasta steps/1-performance (O exemplo serviu para o próximo passo)
- [x] Qual a estratégia mais rápida para normalização das strings?
    - De/para com um range fixado de caracteres conhecidos (pt-BR)
    - Decodificação híbrida para diferenciar caracteres ASCII dos demais.
    - O exemplo prático do melhor resultado que obtive (até agora rss) está em steps/2-normalize
        - 9120418 operações em 2.563s, 131.3 ns/op
- [x] Como ler grandes arquivos em buffer e fazer o parse corretamente?
    - Utilizei o buffio, disponível da própria linguagem
        - Encontrei uma melhoria na porformance setando manualmente o tamanho de buffer de leitura
    - O exemplo prático com o melhor resultado que obtive está em steps/3-parsing
        - 164 operações em 2.052s, 6934582 ns/op
- [x] Como enviar inserts em batch para o banco?
    - [x] Definir estrutura da tabela e como criá-la no banco
        - Não utilizei valores fixos para o tamanho dos campos (ex varchar(50)), por dois motivos:
            - A decisão do tamanho apenas pela amostragem da base fictícia pode trazer problemas futuros em um caso real
            - A diferença de performance é mínima, mas é cabível caso exista um contrato definido para este arquivo
        - O uso de índices é crucial para otimizar as consultas em tabelas realmente grandes
            - Apesar comprometer um pouco a performance do insert, deixei um exemplo como prova de conhecimento
        - 2 operações em 2.046s, 583320104 ns/op
- [] O copyfrom com paralelismo, é mais rápido?
- [] Criar uma solução com tudo o que foi testado